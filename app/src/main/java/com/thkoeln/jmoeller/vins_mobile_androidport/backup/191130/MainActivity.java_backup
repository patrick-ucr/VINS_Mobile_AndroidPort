package com.thkoeln.jmoeller.vins_mobile_androidport;
// Android
import android.Manifest;
import android.app.Activity;
import android.content.Context;
import android.content.pm.PackageInfo;
import android.content.pm.PackageManager;
import android.graphics.Bitmap;
import android.graphics.Canvas;
import android.graphics.ImageFormat;
import android.graphics.Paint;
import android.graphics.RectF;
import android.graphics.SurfaceTexture;
import android.hardware.Sensor;
import android.hardware.SensorManager;
import android.hardware.TriggerEvent;
import android.hardware.TriggerEventListener;
import android.hardware.camera2.CameraAccessException;
import android.hardware.camera2.CameraCaptureSession;
import android.hardware.camera2.CameraCharacteristics;
import android.hardware.camera2.CameraDevice;
import android.hardware.camera2.CameraManager;
import android.hardware.camera2.CaptureRequest;
import android.hardware.camera2.params.StreamConfigurationMap;
import android.media.Image;
import android.media.ImageReader;
import android.net.wifi.WifiInfo;
import android.net.wifi.WifiManager;
import android.os.Build;
import android.os.Environment;
import android.os.Handler;
import android.os.HandlerThread;
import android.os.Process;
import android.os.SystemClock;
import androidx.annotation.NonNull;
//import android.support.annotation.NonNull;
import androidx.core.app.ActivityCompat;
//import android.support.v4.app.ActivityCompat;
import androidx.core.content.ContextCompat;
//import android.support.v4.content.ContextCompat;
import 	androidx.appcompat.app.AppCompatActivity;
//import android.support.v7.app.AppCompatActivity;
import android.os.Bundle;
import android.util.Log;
import android.util.Range;
import android.util.Rational;
import android.util.Size;
import android.view.Display;
import android.view.MotionEvent;
import android.view.Surface;
import android.view.SurfaceView;
import android.view.TextureView;
import android.view.View;
import android.view.WindowManager;
import android.widget.CompoundButton;
import android.widget.ImageView;
import android.widget.SeekBar;
import android.widget.Switch;
import android.widget.TextView;
// Java
import java.io.File;
import java.io.IOException;
import java.io.InputStream;
import java.nio.ByteBuffer;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.io.FileOutputStream;
import java.util.Map;
// OpenCV
import org.opencv.android.OpenCVLoader;
import org.opencv.android.Utils;
import org.opencv.core.Core;
import org.opencv.core.CvType;
import org.opencv.core.Mat;
import org.opencv.core.MatOfDMatch;
import org.opencv.core.MatOfDouble;
import org.opencv.core.MatOfRect;
import org.opencv.core.Point;
import org.opencv.core.Rect;
import org.opencv.core.Scalar;
import org.opencv.imgcodecs.Imgcodecs;
import org.opencv.imgproc.Imgproc;
import org.opencv.ml.RTrees;
import org.opencv.ml.SVM;
import org.opencv.objdetect.CascadeClassifier;
import org.opencv.objdetect.HOGDescriptor;

import com.google.android.gms.tasks.OnFailureListener;
import com.google.android.gms.tasks.OnSuccessListener;
import com.thkoeln.jmoeller.vins_mobile_androidport.env.ImageUtils;
import com.thkoeln.jmoeller.vins_mobile_androidport.tracking.MultiBoxTracker;
// Nearby Connection API
import com.google.android.gms.nearby.Nearby;
import com.google.android.gms.nearby.connection.AdvertisingOptions;
import com.google.android.gms.nearby.connection.ConnectionInfo;
import com.google.android.gms.nearby.connection.ConnectionLifecycleCallback;
import com.google.android.gms.nearby.connection.ConnectionResolution;
import com.google.android.gms.nearby.connection.ConnectionsClient;
import com.google.android.gms.nearby.connection.DiscoveredEndpointInfo;
import com.google.android.gms.nearby.connection.DiscoveryOptions;
import com.google.android.gms.nearby.connection.EndpointDiscoveryCallback;
import com.google.android.gms.nearby.connection.Payload;
import com.google.android.gms.nearby.connection.PayloadCallback;
import com.google.android.gms.nearby.connection.PayloadTransferUpdate;
import com.google.android.gms.nearby.connection.PayloadTransferUpdate.Status;
import com.google.android.gms.nearby.connection.Strategy;

/**
 * {@link MainActivity} only activity
 * manages camera input, texture output
 * textViews and buttons
 */
public class MainActivity extends AppCompatActivity implements TextureView.SurfaceTextureListener{

    private static boolean ARchoice = false; // false
    private static final String TAG = "MainActivity";

    static {
        System.loadLibrary("opencv_java3");
        if (OpenCVLoader.initDebug()){
            Log.i(TAG, "OpenCV loaded successfully");
        }
    }


    // needed for permission request callback
    private static final int PERMISSIONS_REQUEST_CODE = 1;//12345

    // camera2 API Camera
    private CameraDevice camera;
    // Back cam, 1 would be the front facing one
    private String cameraID = "0";

    // Texture View to display the camera picture, or the vins output
    private TextureView textureView;
    private Size previewSize;
    private CaptureRequest.Builder previewBuilder;
    private ImageReader imageReader;

    // Handler for Camera Thread
    private Handler handler;
    private HandlerThread threadHandler;

    // Cam parameters
    private final int imageWidth = 640;
    private final int imageHeight = 480;//xukan origin 480



    int displayWidth;
    int displayHeight;


    private final int framesPerSecond = 30; //30
    
    /** Adjustment to auto-exposure (AE) target image brightness in EV */
    private final int aeCompensation = 0;
//    private final int aeCompensation = -1;
    
    private Surface surface;
    
    // JNI Object
    private VinsJNI vinsJNI;

    // TextViews
    private TextView tvX;
    private TextView tvY;
    private TextView tvZ;
    private TextView tvTotal;
    private TextView tvLoop;
    private TextView tvFeature;
    private TextView tvBuf;
    private OverlayView trackingOverlay;
    
    // ImageView for initialization instructions
    private ImageView ivInit;
    private SurfaceView surfaceView;
    private Canvas surfaceCanvas;

    // directory path for BRIEF config files
    private final String directoryPathBriefFiles = "/storage/emulated/0/VINS";

    // Distance of virtual Cam from Center
    // could be easily manipulated in UI later
    private float virtualCamDistance = 2;
    private final float minVirtualCamDistance = 2;
    private final float maxVirtualCamDistance = 40;

    private static int countVINS;
    private static long startActivityMs;

    private SensorManager sensorManager;
    private Sensor sensor;
    private TriggerEventListener triggerEventListener;

    private CascadeClassifier cascadeClassifier = null;
    private HOGDescriptor hogDescriptor = null;
    static final int kMaxChannelValue = 262143;
    private byte[][] yuvBytes = new byte[3][];
    private int[] rgbBytes = null;
    private Runnable imageConverter;
    private Runnable objectDetector; // using cascade classifier
    private Runnable drawingThread;
    private boolean detecting_objects = false;
    private boolean drawing_detections = false;
    private Bitmap rgbFrameBitmap = null;
    private Bitmap drawBitmap = null;
    private boolean updatedDrawBitmap = false;
    private Mat rgbFrameMat = new Mat(imageHeight,imageWidth, CvType.CV_8UC4);

    private DNNObjectDetection playerDetector;
    private DNNObjectDetection tvDetector;
    private int timestamp = 0;
    private Activity appActivity;

    public static final Strategy STRATEGY = Strategy.P2P_CLUSTER;
    //public static final String SERVICE_ID = "com.thkoeln.jmoeller.vins_mobile_androidport";
    /** Our handler to Nearby Connections. */
    private ConnectionsClient mConnectionsClient;

    /** The devices we've discovered near us. */
    private final Map<String, Endpoint> mDiscoveredEndpoints = new HashMap<>();

    /**
     * The devices we have pending connections to. They will stay pending until we call {@link
     * #acceptConnection(Endpoint)} or {@link #rejectConnection(Endpoint)}.
     */
    private final Map<String, Endpoint> mPendingConnections = new HashMap<>();

    /**
     * The devices we are currently connected to. For advertisers, this may be large. For discoverers,
     * there will only be one entry in this map.
     */
    private final Map<String, Endpoint> mEstablishedConnections = new HashMap<>();

    /**
     * True if we are asking a discovered device to connect to us. While we ask, we cannot ask another
     * device.
     */
    private boolean mIsConnecting = false;

    /** True if we are discovering. */
    private boolean mIsDiscovering = false;

    /** True if we are advertising. */
    private boolean mIsAdvertising = false;


    private final String codeName = "green";
    private final Endpoint localEndpoint = new Endpoint("3", "red");



    private final PayloadCallback payloadCallback =
            new PayloadCallback() {
                @Override
                public void onPayloadReceived(String endpointId, Payload payload) {
                    Log.i(TAG, "Nearby: onPayloadReceived()");
                    //opponentChoice = GameChoice.valueOf(new String(payload.asBytes(), UTF_8));
                }

                @Override
                public void onPayloadTransferUpdate(String endpointId, PayloadTransferUpdate update) {
                    Log.i(TAG, "Nearby: onPayloadTransferUpdate()");
                    //if (update.getStatus() == Status.SUCCESS && myChoice != null && opponentChoice != null) {
                        //finishRound();
                    //}
                }
            };
    // Callbacks for finding other devices
    private final EndpointDiscoveryCallback endpointDiscoveryCallback =
            new EndpointDiscoveryCallback() {
                @Override
                public void onEndpointFound(String endpointId, DiscoveredEndpointInfo info) {
                    Log.i(TAG, String.format("onEndpointFound: endpoint %s %s found, connecting",
                            endpointId,info.getEndpointName()));
                    //if (getPackageName().equals(info.getServiceId())){
                    //
                    //}
                    mConnectionsClient.requestConnection(localEndpoint.getName(), endpointId, connectionLifecycleCallback);
                }

                @Override
                public void onEndpointLost(String endpointId) {
                    Log.i(TAG, String.format("onEndpointLost: %s",endpointId));
                }
            };

    // Callbacks for connections to other devices
    private final ConnectionLifecycleCallback connectionLifecycleCallback =
            new ConnectionLifecycleCallback() {
                @Override
                public void onConnectionInitiated(String endpointId, ConnectionInfo connectionInfo) {
                    Log.i(TAG, "onConnectionInitiated: accepting connection");
                    mConnectionsClient.acceptConnection(endpointId, payloadCallback);
                    //opponentName = connectionInfo.getEndpointName();
                }

                @Override
                public void onConnectionResult(String endpointId, ConnectionResolution result) {
                    if (result.getStatus().isSuccess()) {
                        Log.i(TAG, "onConnectionResult: connection successful");

                        //mConnectionsClient.stopDiscovery();
                        //mConnectionsClient.stopAdvertising();

                        //opponentEndpointId = endpointId;
                        //setOpponentName(opponentName);
                        //setStatusText(getString(R.string.status_connected));
                        //setButtonState(true);
                    } else {
                        Log.i(TAG, "onConnectionResult: connection failed");
                    }
                }

                @Override
                public void onDisconnected(String endpointId) {
                    Log.i(TAG, "onDisconnected: disconnected from the opponent");
                    //resetGame();
                }
            };
    /**
     * Gets Called after App start
     */
    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);
        getWindow().addFlags(WindowManager.LayoutParams.FLAG_KEEP_SCREEN_ON);

        // first make sure the necessary permissions are given
        checkPermissionsIfNeccessary();
        
        if(!checkBriefFileExistance()) {
            Log.e(TAG, "Brief files not found here: " + directoryPathBriefFiles);
            finish();
        }
        Display d = ((WindowManager)getSystemService(Context.WINDOW_SERVICE)).getDefaultDisplay();
        displayWidth = d.getWidth();
        displayHeight = d.getHeight();
        initLooper();
        initVINS();
        initViews();
        countVINS = 0;
        startActivityMs = System.currentTimeMillis();
        initializeOpenCVDependencies();
        rgbFrameBitmap = Bitmap.createBitmap(imageWidth,imageHeight, Bitmap.Config.ARGB_8888);
        drawBitmap = Bitmap.createBitmap(imageWidth,imageHeight, Bitmap.Config.ARGB_8888);
        //MovementDetector.getInstance(this);
        initSensor();
        final Context appContext = getApplicationContext();
        playerDetector = new DNNObjectDetection(appContext);
        appActivity = (Activity) this;
        playerDetector.init(appActivity, imageWidth,imageHeight, "person");
        tvDetector = new DNNObjectDetection(appContext);
        tvDetector.init(appActivity,imageWidth,imageHeight,"tv");
        mConnectionsClient = Nearby.getConnectionsClient(this);

        WifiManager manager = (WifiManager) appContext.getSystemService(Context.WIFI_SERVICE);
        WifiInfo info = manager.getConnectionInfo();
        String macAddress = info.getMacAddress();
        Log.i(TAG, String.format("MAC Address: %s", macAddress));
        startAdvertising();
        startDiscovery();
    }

    /** Starts looking for other players using Nearby Connections. */
    private void startDiscovery() {
        // Note: Discovery may fail. To keep this demo simple, we don't handle failures.
        Log.i(TAG, "Nearby: startDiscovery()");
        mIsDiscovering = true;
        mDiscoveredEndpoints.clear();
        mConnectionsClient.startDiscovery(
                getPackageName(), endpointDiscoveryCallback,
                new DiscoveryOptions.Builder().setStrategy(STRATEGY).build())
        .addOnSuccessListener(
                new OnSuccessListener<Void>() {
                    @Override
                    public void onSuccess(Void aVoid) {
                        Log.i(TAG, "startDiscovery onSuccess");
                    }
                }
        ).addOnFailureListener(
                new OnFailureListener() {
                    @Override
                    public void onFailure(@NonNull Exception e) {
                        Log.i(TAG, "startDiscovery onFailure!!");
                    }
                }
        );
    }

    /** Broadcasts our presence using Nearby Connections so other players can find us. */
    private void startAdvertising() {
        // Note: Advertising may fail. To keep this demo simple, we don't handle failures.
        Log.i(TAG, "Nearby: startAdvertising()");
        mIsAdvertising = true;

        mConnectionsClient.startAdvertising(
                localEndpoint.getName(), getPackageName(), connectionLifecycleCallback,
                new AdvertisingOptions.Builder().setStrategy(STRATEGY).build())
        .addOnSuccessListener(
                new OnSuccessListener<Void>() {
                    @Override
                    public void onSuccess(Void aVoid) {
                        Log.v(TAG, String.format("Now advertising endpoint %s",localEndpoint.getName()));
                    }
                }
        )
        .addOnFailureListener(
                new OnFailureListener() {
            @Override
            public void onFailure(@NonNull Exception e) {
                mIsAdvertising = false;
                Log.v(TAG, "startAdvertising failed");
            }
        });
    }
    
    private void initSensor(){
        sensorManager = (SensorManager) getSystemService(Context.SENSOR_SERVICE);
        sensor = sensorManager.getDefaultSensor(Sensor.TYPE_SIGNIFICANT_MOTION);

        triggerEventListener = new TriggerEventListener() {
            @Override
            public void onTrigger(TriggerEvent event) {
                Log.i(TAG, "Significant motion detected!!!");
            }
        };

        sensorManager.requestTriggerSensor(triggerEventListener, sensor);
    }
    private void initializeOpenCVDependencies() {

        try {
            // Copy the resource into a temp file so OpenCV can load it
            InputStream is = getResources().openRawResource(R.raw.haarcascade_fullbody);
            File cascadeDir = getDir("cascade", Context.MODE_PRIVATE);
            // clear data cache in app folder "cascade"
            if (cascadeDir.isDirectory()){
                String[] children = cascadeDir.list();
                for (String c : children){
                    new File(cascadeDir, c).delete();
                }
            }
            Log.i(TAG, "cascadeDir: "+cascadeDir.getAbsolutePath());
            File mCascadeFile = new File(cascadeDir, "cascade.xml");
            Log.i(TAG, String.format("cascadeDir mCascadeFile: %s size: %d",mCascadeFile.getAbsolutePath(),mCascadeFile.length()));
            FileOutputStream os = new FileOutputStream(mCascadeFile);

            byte[] buffer = new byte[4096];
            int bytesRead;
            while ((bytesRead = is.read(buffer)) != -1) {
                os.write(buffer,0,bytesRead);
            }
            is.close();
            os.close();
            Log.i(TAG, String.format("cascadeDir mCascadeFile: %s size: %d",mCascadeFile.getAbsolutePath(),mCascadeFile.length()));
            // Load the cascade classifier
            cascadeClassifier = new CascadeClassifier(mCascadeFile.getAbsolutePath());
            //cascadeClassifier.load(mCascadeFile.getAbsolutePath());

        } catch (Exception e) {
            Log.e("OpenCVActivity", "Error loading cascade", e);
        }
        if (cascadeClassifier != null){
            Log.i(TAG, "cascadeClassifier not null");
        }

        hogDescriptor = new HOGDescriptor();
        hogDescriptor.setSVMDetector(HOGDescriptor.getDefaultPeopleDetector());

        if (rgbBytes == null){
            rgbBytes = new int[imageWidth * imageHeight];
        }
    }
    /**
     * check if necessary files brief_k10L6.bin and brief_pattern.yml exist in the directoryPathBriefFiles
     * @return true if files are existent and read and writable
     */
    private boolean checkBriefFileExistance() {
        File directoryFile = new File(directoryPathBriefFiles);
        //Checking the availability state of the External Storage.
        String state = Environment.getExternalStorageState();
        if (!Environment.MEDIA_MOUNTED.equals(state)) {

            //If it isn't mounted - we can't write into it.
            return false;
        }

        //String externalStoragePath =
        if(!directoryFile.exists())
            return false;

        String filepathVoc = directoryFile.getAbsolutePath() + File.separator + "brief_k10L6.bin";
        File vocFile = new File(filepathVoc);
        Log.d(TAG, "Filepath: " + filepathVoc + 
                   " File Exists: " + vocFile.exists() + 
                   " File Write: " + vocFile.canWrite() +  
                   " File Read: " + vocFile.canRead());
        if(!vocFile.exists() || !vocFile.canRead() || !vocFile.canWrite())
            return false;
        
        String filepathPattern = directoryFile + File.separator + "brief_pattern.yml";
        File patternFile = new File(filepathPattern);
        Log.d(TAG, "Filepath: " + filepathPattern + 
                   " File Exists: " + patternFile.exists() + 
                   " File Write: " + patternFile.canWrite() +  
                   " File Read: " + patternFile.canRead());
        if(!patternFile.exists() || !patternFile.canRead() || !patternFile.canWrite())
            return false;
        
        return true;
    }

    /**
     * Starting separate thread to handle camera input
     */
    private void initLooper() {
        threadHandler = new HandlerThread("Camera2Thread");
        threadHandler.start();
        handler = new Handler(threadHandler.getLooper());
    }

    /**
     * initializes an new VinsJNI Object
     */
    private void initVINS() {
        vinsJNI = new VinsJNI();
        vinsJNI.init();
    }
    
    /**
     * Finding all UI Elements,
     * Setting TextureView Listener to this object.
     */
    private void initViews() {
        tvX = (TextView) findViewById(R.id.x_Label);
        tvY = (TextView) findViewById(R.id.y_Label);
        tvZ = (TextView) findViewById(R.id.z_Label);
        tvTotal = (TextView) findViewById(R.id.total_odom_Label);
        tvLoop = (TextView) findViewById(R.id.loop_Label);
        tvFeature = (TextView) findViewById(R.id.feature_Label);
        tvBuf = (TextView) findViewById(R.id.buf_Label);
        
        ivInit = (ImageView) findViewById(R.id.init_image_view);
        ivInit.setVisibility(View.INVISIBLE);//View.VISIBLE

        textureView = (TextureView) findViewById(R.id.texture_view);
        textureView.setSurfaceTextureListener(this);


        // Define the Switch listeners
        Switch arSwitch = (Switch) findViewById(R.id.ar_switch);
        arSwitch.setOnCheckedChangeListener(new CompoundButton.OnCheckedChangeListener() {
            @Override
            public void onCheckedChanged(CompoundButton buttonView, boolean isChecked) {
                Log.d(TAG,"arSwitch State = " + isChecked);
                ARchoice = isChecked;
                VinsJNI.onARSwitch(isChecked);
            }
        });
        
        Switch loopSwitch = (Switch) findViewById(R.id.loop_switch);
        loopSwitch.setOnCheckedChangeListener(new CompoundButton.OnCheckedChangeListener() {
            @Override
            public void onCheckedChanged(CompoundButton buttonView, boolean isChecked) {
                Log.d(TAG,"loopSwitch State = " + isChecked);
                VinsJNI.onLoopSwitch(isChecked);
            }
        });

        SeekBar zoomSlider = (SeekBar) findViewById(R.id.zoom_slider);
        zoomSlider.setOnSeekBarChangeListener(new SeekBar.OnSeekBarChangeListener() {
            @Override
            public void onProgressChanged(SeekBar seekBar, int progress, boolean fromUser) {
                virtualCamDistance = minVirtualCamDistance + ((float)progress / 100) * (maxVirtualCamDistance - minVirtualCamDistance);
                Log.i(TAG,String.format("virtualCamDistance: %.2f", virtualCamDistance));
            }

            @Override
            public void onStartTrackingTouch(SeekBar seekBar) {  }

            @Override
            public void onStopTrackingTouch(SeekBar seekBar) {  }
        });
    }
    
    /**
     * SurfaceTextureListener interface function 
     * used to set configuration of the camera and start it
     */
    @Override
    public void onSurfaceTextureAvailable(SurfaceTexture surface, int width,
                                          int height) {
        try {
            CameraManager cameraManager = (CameraManager) getSystemService(Context.CAMERA_SERVICE);

            // check permissions
            if (ContextCompat.checkSelfPermission(this, Manifest.permission.CAMERA) != PackageManager.PERMISSION_GRANTED) {
                checkPermissionsIfNeccessary();
                return;
            }
            
            // start up Camera (not the recording)
            cameraManager.openCamera(cameraID, cameraDeviceStateCallback, handler);
        } catch (CameraAccessException e) {
            e.printStackTrace();
        }
    }

    @Override
    public void onSurfaceTextureSizeChanged(SurfaceTexture surface, int width, int height) {}

    @Override
    public boolean onSurfaceTextureDestroyed(SurfaceTexture surface) {
        return false;
    }

    @Override
    public void onSurfaceTextureUpdated(SurfaceTexture surface) {}

    private CameraDevice.StateCallback cameraDeviceStateCallback = new CameraDevice.StateCallback() {

        @Override
        public void onOpened(CameraDevice cameraDevice) {
            try {
                camera = cameraDevice;
                startCameraView(camera);
            } catch (CameraAccessException e) {
                e.printStackTrace();
            }
        }

        @Override
        public void onDisconnected(CameraDevice camera) {}

        @Override
        public void onError(CameraDevice camera, int error) {}
    };

    /**
     * starts CameraView
     */
    private void startCameraView(CameraDevice camera) throws CameraAccessException {
        SurfaceTexture texture = textureView.getSurfaceTexture();
        
        // to set CameraView size
        texture.setDefaultBufferSize(textureView.getWidth(), textureView.getHeight());
        Log.d(TAG, "texture width: " + textureView.getWidth() + " height: " + textureView.getHeight());
        surface = new Surface(texture);
                
        try {
            // to set request for CameraView
            previewBuilder = camera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
        } catch (CameraAccessException e) {
            e.printStackTrace();
        }

        // to set the format of captured images and the maximum number of images that can be accessed in mImageReader
        imageReader = ImageReader.newInstance(imageWidth, imageHeight, ImageFormat.YUV_420_888, 1);
        //imageReader = ImageReader.newInstance(, 480, ImageFormat.YUV_420_888, 1);

        imageReader.setOnImageAvailableListener(onImageAvailableListener, handler);


        CameraManager cameraManager = (CameraManager) getSystemService(Context.CAMERA_SERVICE);
        CameraCharacteristics characteristics = cameraManager.getCameraCharacteristics(cameraID);
        // get the StepSize of the auto exposure compensation
        Rational aeCompStepSize = characteristics.get(CameraCharacteristics.CONTROL_AE_COMPENSATION_STEP);


        if(aeCompStepSize == null) {
            Log.e(TAG, "Camera doesn't support setting Auto-Exposure Compensation");
            finish();
        }
        Log.d(TAG, "AE Compensation StepSize: " + aeCompStepSize);
        
        int aeCompensationInSteps = aeCompensation * aeCompStepSize.getDenominator() / aeCompStepSize.getNumerator();
        Log.d(TAG, "aeCompensationInSteps: " + aeCompensationInSteps );
        previewBuilder.set(CaptureRequest.CONTROL_AE_EXPOSURE_COMPENSATION, aeCompensationInSteps);
        
        // set the camera output frequency to 30Hz
        previewBuilder.set(CaptureRequest.CONTROL_AE_TARGET_FPS_RANGE, new Range<Integer>(framesPerSecond, framesPerSecond));

        // the first added target surface is for CameraView display
        // the second added target mImageReader.getSurface() 
        // is for ImageReader Callback where it can be access EACH frame
        //mPreviewBuilder.addTarget(surface);
        previewBuilder.addTarget(imageReader.getSurface());

        //output Surface
        List<Surface> outputSurfaces = new ArrayList<>();
        outputSurfaces.add(imageReader.getSurface());
        
        
        camera.createCaptureSession(outputSurfaces, sessionStateCallback, handler);
    }

    private CameraCaptureSession.StateCallback sessionStateCallback = new CameraCaptureSession.StateCallback() {
        @Override
        public void onConfigured(CameraCaptureSession session) {
            try {
                updateCameraView(session);
            } catch (CameraAccessException e) {
                e.printStackTrace();
            }
        }

        @Override
        public void onConfigureFailed(CameraCaptureSession session) {

        }
    };
    /**
     * Starts the RepeatingRequest for 
     */
    protected void fillBytes(final Image.Plane[] planes, final byte[][] yuvBytes) {
        // Because of the variable row stride it's not possible to know in
        // advance the actual necessary dimensions of the yuv planes.
        for (int i = 0; i < planes.length; ++i) {
            final ByteBuffer buffer = planes[i].getBuffer();
            if (yuvBytes[i] == null) {
                Log.d(TAG,String.format("Initializing buffer %d at size %d", i, buffer.capacity()));
                yuvBytes[i] = new byte[buffer.capacity()];
            }
            buffer.get(yuvBytes[i]);
        }
    }

    private void runCascadeClassifier(){


    }

    private void updateCameraView(CameraCaptureSession session)
            throws CameraAccessException {
//        previewBuilder.set(CaptureRequest.CONTROL_AF_MODE, CaptureRequest.CONTROL_AF_MODE_AUTO);
        previewBuilder.set(CaptureRequest.CONTROL_AF_MODE, CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_VIDEO);

        session.setRepeatingRequest(previewBuilder.build(), null, handler);
    }
    
    /**
     *  At last the actual function with access to the image
     */
    private ImageReader.OnImageAvailableListener onImageAvailableListener = new ImageReader.OnImageAvailableListener() {

        /*
         *  The following method will be called every time an image is ready
         *  be sure to use method acquireNextImage() and then close(), otherwise, the display may STOP
         */
        @Override
        public void onImageAvailable(ImageReader reader) {
            // get the newest frame
            Image image = reader.acquireNextImage();
            
            if (image == null) {
                return;
            }
                    
            if (image.getFormat() != ImageFormat.YUV_420_888) {
                Log.e(TAG, "xukan, camera image is in wrong format");
            }else{
                Log.i(TAG, "xukan, camera image is in right format");
            }
            ++timestamp;
            final long currTimestamp = timestamp;
            //RGBA output
            Image.Plane Y_plane = image.getPlanes()[0];
            final int Y_rowStride = Y_plane.getRowStride();
            Image.Plane U_plane = image.getPlanes()[1];
            final int UV_rowStride = U_plane.getRowStride();
            final int UV_pixelStride = U_plane.getPixelStride();
            Image.Plane V_plane = image.getPlanes()[2];


            int currentRotation = getWindowManager().getDefaultDisplay().getRotation();
            boolean isScreenRotated = currentRotation != Surface.ROTATION_90;
            Log.i(TAG, String.format("Screen rotated?: %b",isScreenRotated));
            // pass image to c++ part
            countVINS++;
            float vinsFPS =  ( (float)countVINS /(float)(System.currentTimeMillis()-startActivityMs)) * 1000.0f;
            Log.i(TAG,String.format("VINS frame rate: %.2f", vinsFPS));
            Log.i(TAG,"Before VinsJNI.onImageAvailable");

            VinsJNI.onImageAvailable(image.getWidth(), image.getHeight(),
                    Y_rowStride, Y_plane.getBuffer(),
                    UV_rowStride, U_plane.getBuffer(), V_plane.getBuffer(),
                    surface, image.getTimestamp(), isScreenRotated,
                    virtualCamDistance);


            // run the updateViewInfo function on the UI Thread so it has permission to modify it
            runOnUiThread(new Runnable() {
                public void run() {
                    VinsJNI.updateViewInfo(tvX, tvY, tvZ, tvTotal, tvLoop, tvFeature, tvBuf, ivInit);
                }
            });

            synchronized (this) {
                fillBytes(image.getPlanes(), yuvBytes);
            }

            ImageUtils.convertYUV420ToARGB8888(
                    yuvBytes[0],
                    yuvBytes[1],
                    yuvBytes[2],
                    imageWidth,
                    imageHeight,
                    Y_rowStride,
                    UV_rowStride,
                    UV_pixelStride,
                    rgbBytes
            );

            rgbFrameBitmap.setPixels(rgbBytes,0,imageWidth,0,0,imageWidth,imageHeight);

            image.close();

            playerDetector.onFrame(
                    imageWidth,
                    imageHeight,
                    Y_rowStride,
                    appActivity,
                    yuvBytes[0],
                    timestamp
            );

            int dnn_detection_period = 60;
            if (countVINS % dnn_detection_period == 0) {
                playerDetector.detect(rgbFrameBitmap, yuvBytes[0], currTimestamp);
            }

            List<RectF> listBbox = playerDetector.getTrackedBbox();
            Log.i(TAG, "listBbox size: "+listBbox.size());
            for (RectF bbox : listBbox){
                Log.i(TAG, "Bbox RectF: "+bbox);
                int dist_ = VinsJNI.getObjectDistance(
                        (int) bbox.left,
                        (int) bbox.top,
                        (int) bbox.right,
                        (int) bbox.bottom
                );

                Log.i(TAG, "Object distance: "+dist_);
            }
        }
    };

    private void saveMatToExternal(Mat mat, int id){
        Imgproc.cvtColor(mat,mat,Imgproc.COLOR_RGB2BGR);
        String filename =  String.format("%010d.jpg",id);
        String fileFullPath = directoryPathBriefFiles + File.separator
                + "saved_images" + File.separator + filename;
        Imgcodecs.imwrite(fileFullPath,mat);
    }

    private void objectDetector(){
        /*
            Utils.bitmapToMat(rgbFrameBitmap,rgbFrameMat);

            objectDetector = new Runnable() {
                @Override
                public void run() {
                    detecting_objects = true;
                    Process.setThreadPriority(Process.THREAD_PRIORITY_LOWEST);
                    if (cascadeClassifier == null || hogDescriptor == null) return;
                    Mat greyFrameMat = new Mat();
                    Imgproc.cvtColor(rgbFrameMat,greyFrameMat,Imgproc.COLOR_RGB2GRAY);
                    Imgproc.equalizeHist(greyFrameMat,greyFrameMat);
                    Mat lap = new Mat();
                    Imgproc.Laplacian(greyFrameMat,lap,3);
                    MatOfDouble median = new MatOfDouble();
                    MatOfDouble std = new MatOfDouble();
                    Core.meanStdDev(lap, median, std);
                    double varOfLap = Math.pow(std.get(0,0)[0],2);
                    Log.i(TAG, String.format("Variance of Laplace: %.4f",varOfLap));
                    Log.i(TAG, String.format("countVINS %010d",countVINS));
                    if (varOfLap > 1000.0){ // Variance of Laplace sharpness threshold
                        MatOfRect locationsCascade = new MatOfRect();
                        MatOfRect locationsHOG = new MatOfRect();
                        MatOfDouble weights = new MatOfDouble(); //for hog
                        cascadeClassifier.detectMultiScale(greyFrameMat,locationsCascade);
                        Mat bgrFrameMat = new Mat();
                        Imgproc.cvtColor(rgbFrameMat,bgrFrameMat, Imgproc.COLOR_RGB2BGR);
                        hogDescriptor.detectMultiScale(bgrFrameMat,locationsHOG,weights);
                        Log.i(TAG, String.format("Locations Cascade: %d HOG: %d ",
                                locationsCascade.toList().size(),locationsHOG.toList().size()));
                        List<Rect> locationsListCascade = locationsCascade.toList();
                        for (Rect rect : locationsListCascade) {
                            Imgproc.rectangle(bgrFrameMat,
                                    new Point(rect.x,rect.y),
                                    new Point(rect.x + rect.width , rect.y + rect.height),
                                    new Scalar(255,0,0),
                                    5);
                        }
                        List<Rect> locationsListHog = locationsHOG.toList();
                        for (Rect rect : locationsListHog) {
                            Imgproc.rectangle(bgrFrameMat,
                                    new Point(rect.x,rect.y),
                                    new Point(rect.x + rect.width , rect.y + rect.height),
                                    new Scalar(0,0,255),
                                    5);
                        }
                        Mat rgbFrameMatToDraw = new Mat();
                        Imgproc.cvtColor(bgrFrameMat,rgbFrameMatToDraw,Imgproc.COLOR_BGR2RGB);
                        Utils.matToBitmap(rgbFrameMatToDraw,drawBitmap);
                        updatedDrawBitmap = true;
                        //saveMatToExternal(rgbFrameMatToDraw,countVINS);

                    }
                    detecting_objects = false;
                }
            };

            final int OBJ_DET_PERIOD = 5; // detect objects every ... frame
            if (!detecting_objects && countVINS % OBJ_DET_PERIOD == 0) {
                objectDetector.run();
            }
            drawingThread = new Runnable() {
                @Override
                public void run() {
                    updatedDrawBitmap = false;
                    ivInit.setImageBitmap(drawBitmap);
                    drawing_detections = false;
                }
            };

            if (drawBitmap != null &&
                    !drawing_detections &&
                        updatedDrawBitmap == true){
                drawing_detections = true;
                runOnUiThread(drawingThread);
            }*/
        // pass the current device's screen orientation to the c++ part
        // save frames to external
        //saveMatToExternal(rgbFrameMat, countVINS);
    }
    /**
     * shutting down onPause
     */
    protected void onPause() {
        if (null != camera) {
            camera.close();
            camera = null;
        }
        if (null != imageReader) {
            imageReader.close();
            imageReader = null;
        }
        
        VinsJNI.onPause();
        
        super.onPause();
    }

    /**
     * @return true if permissions where given
     */
    private boolean checkPermissionsIfNeccessary() {
        try {
            PackageInfo info = getPackageManager().getPackageInfo(this.getPackageName(), PackageManager.GET_PERMISSIONS);
            if (info.requestedPermissions != null) {
                List<String> permissionsNotGrantedYet = new ArrayList<>(info.requestedPermissions.length);
                for (String p : info.requestedPermissions) {
                    Log.i(TAG, String.format("Requested permission: %s",p));
                    if (ContextCompat.checkSelfPermission(this, p) != PackageManager.PERMISSION_GRANTED) {
                        Log.i(TAG, String.format("Not-yet-granted permission: %s",p));
                        permissionsNotGrantedYet.add(p);
                    }
                }
                if(permissionsNotGrantedYet.size() > 0){
                    if (Build.VERSION.SDK_INT < 23) {
                        ActivityCompat.requestPermissions(this, permissionsNotGrantedYet.toArray(new String[permissionsNotGrantedYet.size()]),
                                PERMISSIONS_REQUEST_CODE);
                    } else {
                        Log.i(TAG, "Requesting permissions");
                        requestPermissions(permissionsNotGrantedYet.toArray(new String[permissionsNotGrantedYet.size()]),
                                PERMISSIONS_REQUEST_CODE);
                    }
                    return false;
                }
            }
        } catch (PackageManager.NameNotFoundException e) {
            e.printStackTrace();
        }

        return true;
    }
    
    @Override
    public void onRequestPermissionsResult(int requestCode,
                                           @NonNull String permissions[],
                                           @NonNull int[] grantResults) {

        if(requestCode == PERMISSIONS_REQUEST_CODE) {
            boolean hasAllPermissions = true;
            // If request is cancelled, the result arrays are empty.
            if (grantResults.length == 0)
                hasAllPermissions = false;
            for (String p: permissions){
                Log.i(TAG, String.format("permission: %s",p));
            }
            for (int result : grantResults) {
                if (result != PackageManager.PERMISSION_GRANTED)
                    hasAllPermissions = false;
            }
            Log.i(TAG, String.format("hasAllPermission?: %b",hasAllPermissions));
            if(!hasAllPermissions){
                finish();
            }
        }
    }

    @Override
    public boolean onTouchEvent(MotionEvent e) {
        // MotionEvent reports input details from the touch screen
        // and other input controls. In this case, you are only
        // interested in events where the touch position changed.
        if(ARchoice) {
            float x = e.getX();
            float y = e.getY();
            Log.d("Xukan disply", "displayHeight: " + displayHeight + "; displayWidth: " + displayWidth);
            float yratio = y / displayHeight * imageWidth;//*640
            float xratio = x / displayWidth * imageHeight;//* 480
            VinsJNI.setARTouchPosition(xratio, yratio);
        }
        return true;
    }

    /** Represents a device we can talk to. */
    protected static class Endpoint {
        @NonNull private final String id;
        @NonNull private final String name;

        private Endpoint(@NonNull String id, @NonNull String name) {
            this.id = id;
            this.name = name;
        }

        @NonNull
        public String getId() {
            return id;
        }

        @NonNull
        public String getName() {
            return name;
        }

        @Override
        public boolean equals(Object obj) {
            if (obj instanceof Endpoint) {
                Endpoint other = (Endpoint) obj;
                return id.equals(other.id);
            }
            return false;
        }

        @Override
        public int hashCode() {
            return id.hashCode();
        }

        @Override
        public String toString() {
            return String.format("Endpoint{id=%s, name=%s}", id, name);
        }
    }
}
